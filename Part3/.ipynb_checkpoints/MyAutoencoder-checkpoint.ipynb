{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import torch\n", "import torch.optim as optim"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the architecture"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Autoencoder(torch.nn.Module):\n", "    def __init__(self):\n", "        super(Autoencoder, self).__init__()\n", "        self.encoder = torch.nn.Linear(2, 1)\n", "        self.decoder = torch.nn.Linear(1, 2)\n", "    def forward(self, x):\n", "        z = self.encoder(x)\n", "        x_recon = self.decoder(z)\n", "        return x_recon"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generate data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["D = 2\n", "x = torch.rand(100, D)\n", "x[:, 0] = x[:, 0] + x[:, 1]\n", "x[:, 1] = 0.5 * x[:, 0] + x[:, 1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize autoencoder and optimizer for SGD without momentum"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder_sgd = Autoencoder()\n", "criterion = torch.nn.MSELoss()\n", "optimizer_sgd = optim.SGD(autoencoder_sgd.parameters(), lr=0.01)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize autoencoder and optimizer for SGD with momentum"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder_momentum = Autoencoder()\n", "optimizer_momentum = optim.SGD(autoencoder_momentum.parameters(), lr=0.01, momentum=0.9)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize autoencoder and optimizer for RMSprop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder_rmsprop = Autoencoder()\n", "optimizer_rmsprop = optim.RMSprop(autoencoder_rmsprop.parameters(), lr=0.01, momentum=0.9)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Training loop for SGD without momentum"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_steps = 1000\n", "losses_sgd = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for step in range(num_steps):\n", "    optimizer_sgd.zero_grad()\n", "    x_recon = autoencoder_sgd(x)\n", "    loss = criterion(x_recon, x)\n", "    loss.backward()\n", "    optimizer_sgd.step()\n", "    losses_sgd.append(loss.item())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Training loop for SGD with momentum"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["losses_momentum = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for step in range(num_steps):\n", "    optimizer_momentum.zero_grad()\n", "    x_recon = autoencoder_momentum(x)\n", "    loss = criterion(x_recon, x)\n", "    loss.backward()\n", "    optimizer_momentum.step()\n", "    losses_momentum.append(loss.item())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Training loop for RMSprop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["losses_rmsprop = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for step in range(num_steps):\n", "    optimizer_rmsprop.zero_grad()\n", "    x_recon = autoencoder_rmsprop(x)\n", "    loss = criterion(x_recon, x)\n", "    loss.backward()\n", "    optimizer_rmsprop.step()\n", "    losses_rmsprop.append(loss.item())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the loss versus epochs for all three"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8, 6))\n", "plt.plot(losses_sgd, label='SGD (No Momentum)')\n", "plt.plot(losses_momentum, label='SGD with Momentum')\n", "plt.plot(losses_rmsprop, label='RMSprop with Momentum')\n", "plt.xlabel('Epochs')\n", "plt.ylabel('Loss')\n", "plt.title('Loss vs. Epochs')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot original data, reconstructed data, and encoder weights for RMSprop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8, 6))\n", "plt.scatter(x[:, 0], x[:, 1], color='cyan', label='Original Data')\n", "plt.scatter(x_recon[:, 0].detach(), x_recon[:, 1].detach(), label='Reconstructed Data')\n", "plt.plot([0, autoencoder_rmsprop.encoder.weight[0, 0].item()], [0, autoencoder_rmsprop.encoder.weight[0, 1].item()], '-r', label='Encoder Weights')\n", "plt.xlabel('Dimension 0')\n", "plt.ylabel('Dimension 1')\n", "plt.axis('equal')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate and print weight ratios for RMSprop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["encoder_weight = autoencoder_rmsprop.encoder.weight.data\n", "decoder_weight = autoencoder_rmsprop.decoder.weight.data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate and print weight ratios for RMSprop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["encoder_weight = autoencoder_rmsprop.encoder.weight.data\n", "decoder_weight = autoencoder_rmsprop.decoder.weight.data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratio_dim0_encoder = encoder_weight[0, 0] / decoder_weight[0, 0]\n", "ratio_dim1_encoder = encoder_weight[0, 1] / decoder_weight[0, 0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f'Weight ratio for dimension 0: {ratio_dim0_encoder}')\n", "print(f'Weight ratio for dimension 1: {ratio_dim1_encoder}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Interpretation of results:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Interpretation of Results:\")\n", "print(\"SGD (No Momentum) vs. SGD with Momentum vs. RMSprop:\")\n", "print(\"- SGD (No Momentum) shows standard SGD optimization.\")\n", "print(\"- SGD with Momentum introduces momentum, which can help converge faster and avoid local minima.\")\n", "print(\"- RMSprop combines adaptive learning rates with momentum, potentially leading to more stable convergence.\")\n", "print(\"Comparing weight ratios:\")\n", "print(f'Weight ratio for dimension 0: {ratio_dim0_encoder}')\n", "print(f'Weight ratio for dimension 1: {ratio_dim1_encoder}')\n", "print(\"The weight ratios indicate how the encoder weights relate to the decoder weights.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import csv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a dictionary to store the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_to_save = {\n", "    \"Loss_SGD_No_Momentum\": losses_sgd,\n", "    \"Loss_SGD_with_Momentum\": losses_momentum,\n", "    \"Loss_RMSprop_with_Momentum\": losses_rmsprop,\n", "    \"Weight_Ratio_Dimension_0\": ratio_dim0_encoder,\n", "    \"Weight_Ratio_Dimension_1\": ratio_dim1_encoder\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["CSV name"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["csv_filename = \"autoencoder_results.csv\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Save the data to the CSV file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(csv_filename, \"w\", newline=\"\") as csv_file:\n", "    writer = csv.DictWriter(csv_file, fieldnames=data_to_save.keys())\n\n", "    # Write the header\n", "    writer.writeheader()\n\n", "    # Write the data\n", "    writer.writerow(data_to_save)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Interpretation of results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Interpretation of Results:\")\n", "print('''In this experiment, I trained a simple linear autoencoder using different optimization techniques: Stochastic Gradient Descent (SGD) with no momentum, SGD with momentum, and RMSprop. The goal was to understand how these optimization methods affect the learning process and the weight ratios between the encoder and decoder."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["In the first case, with SGD and no momentum, we observed standard gradient descent optimization. This method slowly adjusted the weights to minimize the mean squared error (MSE) loss between the original data and its reconstructions. As a result, it took more steps to converge to an optimal solution."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["In the second case, with SGD and momentum (0.9), we introduced momentum to the optimization process. Momentum helps accelerate convergence and avoid getting stuck in local minima. This was reflected in faster convergence and a more efficient learning process."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["In the third case, using RMSprop with momentum (0.9), we combined adaptive learning rates with momentum. RMSprop adapts the learning rate for each weight individually, making it even more stable and efficient in converging to an optimal solution."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["The key insight from comparing these methods was the weight ratios between the encoder and decoder. During the initial run, the weight ratio for dimension 0 was approximately 1.83, and for dimension 1, it was around 1.95. These weight ratios indicate how the encoder weights relate to the decoder weights."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}